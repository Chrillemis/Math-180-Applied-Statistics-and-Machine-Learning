{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from ISLP.models import ModelSpec as MS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hitters = pd.read_csv('C:\\\\Users\\\\lorentsen\\\\Documents\\\\Python\\\\Math-180-Applied-Statistics-and-Machine-Learning\\\\ISLRv2_data\\\\ALL CSV FILES - 2nd Edition\\\\Hitters.csv')\n",
    "Hitters.dropna(inplace=True)\n",
    "y = Hitters['Salary']\n",
    "x = Hitters.drop('Salary', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1\n",
    "### part a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.astype({'AtBat': 'float64', 'Hits': 'float64', 'HmRun': 'float64', 'Runs': 'float64', 'RBI': 'float64', 'Walks': 'float64', 'Years': 'float64', 'CAtBat': 'float64', 'CHits': 'float64', 'CHmRun': 'float64', 'CRuns': 'float64', 'CRBI': 'float64', 'CWalks': 'float64', 'PutOuts': 'float64', 'Assists': 'float64', 'Errors': 'float64'})\n",
    "for i in range(0, x.shape[1]):\n",
    "    if x.iloc[:, i].dtype == 'object':\n",
    "        continue\n",
    "    x.iloc[:,i] = (x.iloc[:, i] - x.iloc[:, i].mean())/x.iloc[:, i].std()\n",
    "\n",
    "y = (y - y.mean())/y.std()\n",
    "x['NewLeague'] = x['NewLeague'].map({'A': 1, 'N': 0})\n",
    "x['League'] = x['League'].map({'A': 1, 'N': 0})\n",
    "x['Division'] = x['Division'].map({'E': 1, 'W': 0})\n",
    "# print(x.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AtBat       -0.658632\n",
       "Hits         0.755723\n",
       "HmRun        0.080603\n",
       "Runs        -0.121588\n",
       "RBI         -0.047869\n",
       "Walks        0.291328\n",
       "Years       -0.021399\n",
       "CAtBat      -0.892974\n",
       "CHits        0.138303\n",
       "CHmRun      -0.033312\n",
       "CRuns        1.132763\n",
       "CRBI         0.581068\n",
       "CWalks      -0.475808\n",
       "League      -0.168323\n",
       "Division     0.206751\n",
       "PutOuts      0.174039\n",
       "Assists      0.122905\n",
       "Errors      -0.052294\n",
       "NewLeague    0.020377\n",
       "dtype: float64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# newmodel = MS(x, intercept = False)\n",
    "# X = newmodel.fit_transform(x)\n",
    "# Y = y\n",
    "model = sm.OLS(y, x).fit()\n",
    "model.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part c)\n",
    "\n",
    "We have\n",
    "\\begin{equation}\n",
    "f(X) = \\beta_0 + \\sum^K_{k=1} \\beta_k h_k(X)\n",
    "\\end{equation}\n",
    "where $h_k$ is our activation function, which is just connected to one predictor for each $k$. We can rewrite this as\n",
    "\\begin{equation}\n",
    "f(X) = \\beta_0 +\\sum^p_{k=1} \\beta_k X_k\n",
    "\\end{equation}\n",
    "Which is just linear regression.\n",
    "\n",
    "### part d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "newmodel = MS(x, intercept = False)\n",
    "X = newmodel.fit_transform(x)\n",
    "Y = y\n",
    "\n",
    "# X['NewLeague'] = X['NewLeague'].map({'A': 1, 'N': 0})\n",
    "# X['League'] = X['League'].map({'A': 1, 'N': 0})\n",
    "# X['Division'] = X['Division'].map({'E': 1, 'W': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(263, 19)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lorentsen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "modelnn = keras.Sequential(\n",
    "    [\n",
    "        # Input(shape),\n",
    "        layers.Dense(1, activation = None, input_shape = (X.shape[1],)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x26cdd26df90>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelnn.compile(loss='mean_squared_error', optimizer='adam')\n",
    "modelnn.fit(X, Y, epochs=200, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                glm        nn\n",
      "AtBat     -0.658632  0.022274\n",
      "Hits       0.755723 -0.091555\n",
      "HmRun      0.080603 -0.314586\n",
      "Runs      -0.121588  0.023879\n",
      "RBI       -0.047869  0.586889\n",
      "Walks      0.291328  0.002488\n",
      "Years     -0.021399 -0.290138\n",
      "CAtBat    -0.892974  0.267577\n",
      "CHits      0.138303 -0.150033\n",
      "CHmRun    -0.033312  0.035797\n",
      "CRuns      1.132763  0.400545\n",
      "CRBI       0.581068 -0.090109\n",
      "CWalks    -0.475808  0.257955\n",
      "League    -0.168323 -0.180426\n",
      "Division   0.206751  0.234109\n",
      "PutOuts    0.174039  0.171798\n",
      "Assists    0.122905  0.029025\n",
      "Errors    -0.052294 -0.092255\n",
      "NewLeague  0.020377  0.123357\n"
     ]
    }
   ],
   "source": [
    "showparams = pd.DataFrame()\n",
    "# print(model.params)\n",
    "showparams['glm'] = model.params\n",
    "showparams['nn'] = modelnn.get_weights()[0]\n",
    "# showparams.index = model.params.index\n",
    "print(showparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like it does not match the glm very well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adadelta',\n",
       " 'Adafactor',\n",
       " 'Adagrad',\n",
       " 'Adam',\n",
       " 'AdamW',\n",
       " 'Adamax',\n",
       " 'Ftrl',\n",
       " 'Lamb',\n",
       " 'Lion',\n",
       " 'LossScaleOptimizer',\n",
       " 'Nadam',\n",
       " 'Optimizer',\n",
       " 'RMSprop',\n",
       " 'SGD',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'deserialize',\n",
       " 'get',\n",
       " 'legacy',\n",
       " 'schedules',\n",
       " 'serialize']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(keras.optimizers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelnn.compile(loss='mean_squared_error', optimizer = 'Adagrad')\n",
    "modelnn.fit(X, Y, epochs=200, verbose=0)\n",
    "showparams['nn_adagrad'] = modelnn.get_weights()[0]\n",
    "\n",
    "modelnn.compile(loss='mean_squared_error', optimizer = 'Adamax')\n",
    "modelnn.fit(X, Y, epochs=200, verbose=0)\n",
    "showparams['nn_Adamax'] = modelnn.get_weights()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                glm        nn  nn_adagrad  nn_Adamax\n",
      "AtBat     -0.658632  0.022274    0.014089  -0.019052\n",
      "Hits       0.755723 -0.091555   -0.081175  -0.041370\n",
      "HmRun      0.080603 -0.314586   -0.312970  -0.298799\n",
      "Runs      -0.121588  0.023879    0.029169   0.052286\n",
      "RBI       -0.047869  0.586889    0.573196   0.516353\n",
      "Walks      0.291328  0.002488    0.002313   0.009681\n",
      "Years     -0.021399 -0.290138   -0.284870  -0.266854\n",
      "CAtBat    -0.892974  0.267577    0.266789   0.258454\n",
      "CHits      0.138303 -0.150033   -0.145543  -0.132094\n",
      "CHmRun    -0.033312  0.035797    0.041656   0.065285\n",
      "CRuns      1.132763  0.400545    0.401890   0.404398\n",
      "CRBI       0.581068 -0.090109   -0.083940  -0.059121\n",
      "CWalks    -0.475808  0.257955    0.242864   0.182348\n",
      "League    -0.168323 -0.180426   -0.180957  -0.179341\n",
      "Division   0.206751  0.234109    0.235413   0.243338\n",
      "PutOuts    0.174039  0.171798    0.170969   0.171625\n",
      "Assists    0.122905  0.029025    0.027902   0.025951\n",
      "Errors    -0.052294 -0.092255   -0.089661  -0.088812\n",
      "NewLeague  0.020377  0.123357    0.121217   0.108825\n"
     ]
    }
   ],
   "source": [
    "print(showparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They only vary a little betwwen different optimizers, but still far off the glm, which is weird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (2995272198.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[103], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    asd = 1.a\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "asd = 1.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "student   -3.753126\n",
       "balance    0.002795\n",
       "income    -0.000174\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default = pd.read_csv('C:\\\\Users\\\\lorentsen\\\\Documents\\\\Python\\\\Math-180-Applied-Statistics-and-Machine-Learning\\\\ISLRv2_data\\\\ALL CSV FILES - 2nd Edition\\\\Default.csv')\n",
    "\n",
    "default.head()\n",
    "default['default'] = default['default'].map({'No': 0, 'Yes': 1})\n",
    "default['student'] = default['student'].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "X = MS(default.columns.drop('default'), intercept = False).fit_transform(default)\n",
    "Y = default['default']\n",
    "\n",
    "GLMmodel = sm.GLM(\n",
    "    Y\n",
    "    , X\n",
    "    , family = sm.families.Binomial()\n",
    "    )\n",
    "regr = GLMmodel.fit()\n",
    "regr.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part b) \n",
    "See pdf\n",
    "#### part c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lorentsen\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "modelnn = keras.Sequential(\n",
    "    [\n",
    "        layers.Dense(2, activation = 'softmax', input_shape = (X.shape[1],))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### part e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x26cd6f53410>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelnn.compile(loss='categorical_crossentropy', optimizer = 'adam')\n",
    "modelnn.fit(X, keras.utils.to_categorical(Y), epochs=200, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- #### part f) -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glm</th>\n",
       "      <th>nn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>student</th>\n",
       "      <td>-3.753126</td>\n",
       "      <td>-11.810568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance</th>\n",
       "      <td>0.002795</td>\n",
       "      <td>0.018515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>-0.000174</td>\n",
       "      <td>-0.000816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              glm         nn\n",
       "student -3.753126 -11.810568\n",
       "balance  0.002795   0.018515\n",
       "income  -0.000174  -0.000816"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compareparams = pd.DataFrame()\n",
    "compareparams['glm'] = regr.params\n",
    "compareparams['nn'] = np.diff(modelnn.get_weights()[0], axis = 1)\n",
    "compareparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are fairly similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "### part a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.489949664146499"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4.5+np.log(0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7647058823529413"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3/17*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5*0.15 + 1*0.25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
